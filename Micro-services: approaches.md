Задача 1: Обеспечить разработку
Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:

облачная система;
система контроля версий Git;
репозиторий на каждый сервис;
запуск сборки по событию из системы контроля версий;
запуск сборки по кнопке с указанием параметров;
возможность привязать настройки к каждой сборке;
возможность создания шаблонов для различных конфигураций сборок;
возможность безопасного хранения секретных данных (пароли, ключи доступа);
несколько конфигураций для сборки из одного репозитория;
кастомные шаги при сборке;
собственные докер-образы для сборки проектов;
возможность развернуть агентов сборки на собственных серверах;
возможность параллельного запуска нескольких сборок;
возможность параллельного запуска тестов.
Обоснуйте свой выбор.


Решение:
Для обеспечения процесса разработки (хранение исходного кода, непрерывная интеграция и поставка) в облачной среде с соблюдением всех перечисленных требований можно предложить следующую архитектуру на основе следующих инструментов:

GitLab (или GitHub/Bitbucket для альтернатив):

Система контроля версий: GitLab поддерживает систему контроля версий Git, с возможностью создания отдельных репозиториев для каждого сервиса. GitLab CI/CD интегрирован непосредственно с репозиториями, что обеспечивает удобное управление процессами сборки и развёртывания.
Запуск сборок по событию (push, merge requests): GitLab CI/CD автоматически запускает пайплайны сборки при изменении в репозитории, на основе триггеров, связанных с ветками или pull/merge-запросами.
Запуск сборок по кнопке с указанием параметров: GitLab поддерживает ручной запуск сборок с возможностью указания параметров, что полезно для создания сборок с различными конфигурациями (например, сборки с флагом debug или release).
Хранение секретных данных: GitLab предоставляет защищённое хранилище секретов (например, токены, пароли), которое можно привязывать к пайплайнам сборки.
GitLab CI/CD:

Настройки для каждой сборки и шаблоны: GitLab позволяет создать конфигурационные файлы .gitlab-ci.yml для каждого проекта, которые содержат инструкции для пайплайнов. Можно создавать шаблоны для конфигураций и использовать их в разных репозиториях.
Кастомные шаги сборки и Docker-образы: GitLab CI позволяет настраивать кастомные шаги в сборке и использовать собственные Docker-образы для сборки проектов. Например, можно создать кастомный образ с установленными специфическими зависимостями или утилитами.
Несколько конфигураций для одного репозитория: GitLab CI позволяет создавать несколько отдельных пайплайнов для разных веток или конфигураций (например, staging и production), а также использовать разные параметры для одного и того же пайплайна.
Параллельные сборки и тесты: GitLab CI поддерживает параллельное выполнение задач в пайплайне, что позволяет параллельно запускать тесты и сборки.
Агенты сборки на собственных серверах: GitLab поддерживает возможность установки GitLab Runner-ов на собственных серверах или в облаке для выполнения сборок и тестов.
Docker:

Контейнеризация и использование Docker-образов: Docker обеспечивает возможность создания и использования кастомных образов для сборки и тестирования проектов. Все шаги сборки можно контейнеризировать, что позволяет стандартизировать процесс и уменьшить количество ошибок, связанных с разной средой разработки.
Развёртывание агентов на собственных серверах: С помощью Docker можно быстро разворачивать GitLab Runner-ы и другие инструменты CI/CD на собственных серверах, что даёт гибкость в управлении ресурсами.
HashiCorp Vault:

Безопасное хранение секретов: Для более сложных сценариев, требующих управления секретами, можно использовать HashiCorp Vault. Он обеспечит централизованное, безопасное хранение секретных данных с возможностью ротации и ограниченного доступа.
Пример взаимодействия инструментов:
Хранение кода: Исходный код хранится в GitLab, каждый микросервис имеет отдельный репозиторий.

CI/CD: Каждый репозиторий содержит файл .gitlab-ci.yml, который описывает процесс сборки и тестирования. Сборка запускается автоматически при пуше в репозиторий, при создании merge request или вручную с параметрами.

Docker: В процессе сборки используются Docker-образы, которые загружаются из приватного Docker Registry (можно использовать встроенное GitLab Container Registry или внешнее решение, например, Docker Hub). Для сборки кастомных проектов могут использоваться собственные образы.

Secrets: Все секретные данные (токены, пароли) хранятся в GitLab CI/CD Secrets или HashiCorp Vault и доступны в рамках пайплайнов через защищённые переменные окружения.

Параллельное выполнение: Сборки и тесты запускаются параллельно в разных контейнерах, используя GitLab Runners, которые могут быть развернуты на собственных серверах компании для гибкого использования ресурсов.

Преимущества решения:
Облачная система: GitLab поддерживает как облачное, так и собственное развёртывание.
Гибкость и масштабируемость: GitLab CI/CD легко масштабируется, и можно добавлять новые Runner-ы для увеличения производительности.
Удобное управление секретами: За счёт использования GitLab Secrets и HashiCorp Vault можно обеспечить высокую безопасность конфиденциальных данных.
Простота эксплуатации: GitLab и Docker обеспечивают гибкое и стандартизированное решение, которое легко поддерживать и масштабировать.
Широкие возможности конфигурирования: GitLab CI/CD поддерживает кастомные шаги, параметры сборок, шаблоны и параллельные выполнения задач.
Вывод:
GitLab CI/CD в сочетании с Docker и HashiCorp Vault является мощным и гибким решением, которое полностью удовлетворяет всем требованиям для облачной системы управления исходным кодом, непрерывной интеграции и доставки, обеспечивая безопасность, масштабируемость и простоту эксплуатации.


Задача 2: Логи
Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре. Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:

сбор логов в центральное хранилище со всех хостов, обслуживающих систему;
минимальные требования к приложениям, сбор логов из stdout;
гарантированная доставка логов до центрального хранилища;
обеспечение поиска и фильтрации по записям логов;
обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
возможность дать ссылку на сохранённый поиск по записям логов.
Обоснуйте свой выбор.

Решение:

Для сбора и анализа логов в микросервисной архитектуре с учётом всех перечисленных требований я предлагаю использовать решение на основе ELK Stack (Elasticsearch, Logstash, Kibana) с добавлением Filebeat для упрощения сбора логов. Это решение широко используется в микросервисных архитектурах и обладает всеми необходимыми функциями для надёжного сбора, хранения и анализа логов.

Основные компоненты решения
Filebeat:

Сбор логов: Filebeat – это агент, который будет установлен на каждом хосте и собирать логи напрямую из файлов, stdout контейнеров или других источников. Минимальные требования к приложениям заключаются в том, чтобы они выводили логи в stdout (что является стандартной практикой в Docker/Kubernetes).
Доставка логов: Filebeat обеспечивает надёжную доставку логов в централизованное хранилище через логические буферы и поддерживает подтверждения о доставке, что гарантирует отсутствие потерь данных.
Гибкая настройка: Filebeat может быть настроен для отправки логов напрямую в Elasticsearch или через Logstash для дополнительной обработки и фильтрации.
Logstash (опционально):

Обработка логов: Logstash может быть использован для обработки логов перед отправкой в Elasticsearch. Это полезно для фильтрации, обогащения данных, парсинга сообщений и трансформации данных (например, разбора JSON или логов с пользовательским форматом).
Гибкость: Logstash обеспечивает возможность настройки сложных пайплайнов для логов, что позволяет собирать, трансформировать и маршрутизировать логи в зависимости от источников.
Elasticsearch:

Централизованное хранилище логов: Elasticsearch является мощным движком для хранения и поиска данных. Он обеспечивает распределённую архитектуру с высокой доступностью и поддержкой репликации данных, что гарантирует надёжность и скорость работы.
Гибкий поиск: Elasticsearch поддерживает быстрый полнотекстовый поиск и фильтрацию по логам, что важно для анализа и устранения проблем. Можно настроить сложные поисковые запросы по различным параметрам (например, по сервисам, хостам, временным меткам).
Kibana:

Интерфейс для анализа логов: Kibana предоставляет удобный веб-интерфейс для визуализации и анализа логов, что позволяет разработчикам искать и фильтровать записи логов в реальном времени.
Сохранённые поиски и дашборды: Kibana поддерживает возможность сохранения поисков и создания дашбордов. Это даёт возможность разработчикам и другим пользователям сохранять результаты поиска и делиться ими по ссылке.
Доступ разработчиков: Администраторы могут предоставить доступ к Kibana с разграничением прав пользователей, что позволит разработчикам искать логи и сохранять их для дальнейшего анализа.
Пример работы системы:
Сбор логов: Filebeat установлен на каждом хосте (или внутри контейнеров Kubernetes). Он собирает логи из stdout приложений и отправляет их на центральный сервер.

Обработка логов: Логи могут быть отправлены напрямую в Elasticsearch или предварительно обработаны в Logstash для нормализации и фильтрации данных.

Хранение и поиск: Логи хранятся в Elasticsearch, который предоставляет возможность поиска по различным полям, включая метаданные (например, по времени, сервису, уровню логирования).

Интерфейс анализа: Пользователи могут анализировать логи через Kibana, задавать фильтры и сохранять поиски для дальнейшего использования. Например, можно настроить дашборд, который показывает ошибки за последний час по конкретному сервису.

Ссылки на сохранённые поиски: Kibana позволяет создавать сохранённые поиски, которые можно легко передавать в виде ссылок другим разработчикам для анализа.

Преимущества решения:
Централизованный сбор логов: Все логи собираются и сохраняются в одном месте (Elasticsearch), что упрощает мониторинг и анализ.
Минимальные требования к приложениям: Приложения просто выводят логи в stdout, что делает процесс интеграции простым и не требует значительных изменений в коде.
Гарантированная доставка логов: Filebeat и Logstash обеспечивают надёжную доставку логов без потерь даже в случае временных проблем с сетью или хранилищем.
Мощный поиск и фильтрация: Elasticsearch обеспечивает быстрый и гибкий поиск по логам, что помогает оперативно находить и устранять проблемы.
Удобный интерфейс для разработчиков: Kibana предоставляет мощные инструменты для визуализации логов и упрощает доступ разработчиков к системе логирования.
Масштабируемость: ELK Stack может быть легко масштабирован для поддержки большого количества логов и распределённой инфраструктуры.
Безопасность: Elasticsearch и Kibana поддерживают разграничение прав доступа, что позволяет защитить конфиденциальные данные и логи от несанкционированного доступа.
Дополнительные возможности:
Алертинг: Kibana может быть настроена на отправку уведомлений в случае обнаружения аномалий или специфических логов (например, ошибок или предупреждений).
Интеграция с DevOps инструментами: Решение можно легко интегрировать с существующими DevOps инструментами (например, Prometheus, Grafana для метрик) для создания комплексной системы мониторинга и наблюдаемости.
Вывод:
Решение на основе ELK Stack с использованием Filebeat для сбора логов является надёжным, масштабируемым и простым в эксплуатации. Оно полностью удовлетворяет всем требованиям, обеспечивая централизованное хранилище логов, удобный интерфейс для анализа, мощные инструменты поиска и гарантированную доставку логов из любых источников.

Задача 3: Мониторинг
Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре. Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:

сбор метрик со всех хостов, обслуживающих систему;
сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
сбор метрик, специфичных для каждого сервиса;
пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы.
Обоснуйте свой выбор.

Решение:

Для мониторинга микросервисной архитектуры, включающего сбор метрик с хостов и сервисов, оптимальным решением будет использование стека инструментов Prometheus и Grafana. Это проверенная временем комбинация для сбора, хранения и визуализации метрик, которая полностью удовлетворяет всем перечисленным требованиям.

Основные компоненты решения:
Prometheus:

Сбор метрик: Prometheus — это система мониторинга и оповещений с поддержкой Pull-модели. Она регулярно опрашивает таргеты (серверы, контейнеры, приложения) по HTTP/S, собирая метрики в реальном времени. Prometheus поддерживает экспортеры метрик для различных систем и сервисов.
Сбор метрик с хостов (CPU, RAM, HDD, Network): Для мониторинга состояния хостов можно использовать экспортёр node_exporter, который собирает метрики аппаратных ресурсов — CPU, оперативной памяти, дисков и сетевых интерфейсов.
Сбор метрик с каждого сервиса: Для каждого сервиса можно использовать специфические экспортеры или встроенные метрики приложения (например, через client libraries Prometheus). Это позволяет собирать детализированные данные о загрузке CPU, потреблении RAM, дисковом пространстве и сетевой активности для каждого микросервиса.
Гибкая архитектура: Prometheus поддерживает масштабирование и распределённое хранилище, что позволяет легко наращивать мониторинг по мере роста системы.
Сбор специфичных метрик: Prometheus позволяет собирать кастомные метрики, которые могут быть специфичны для каждого сервиса, например, метрики производительности бизнес-логики, задержки запросов и т.д.
Grafana:

Визуализация метрик: Grafana предоставляет мощный и гибкий интерфейс для визуализации данных, собранных Prometheus. С помощью Grafana можно создавать кастомные дашборды, которые отображают данные в виде графиков, таблиц, диаграмм и других визуальных элементов.
Панели для отслеживания состояния системы: Grafana позволяет легко создавать панели мониторинга, которые могут быть настроены под разные нужды. Можно сделать панели для мониторинга общих ресурсов системы (хостов) и отдельные панели для каждого микросервиса.
Агрегация информации и запросы: Grafana поддерживает сложные запросы к данным с использованием PromQL (Prometheus Query Language), что даёт возможность агрегации метрик и анализа в реальном времени. Это полезно для создания отчётов и получения глубокого понимания работы системы.
Alertmanager (дополнение к Prometheus):

Оповещения: Prometheus работает в связке с Alertmanager, который позволяет настроить триггеры на основе метрик и отправлять оповещения (например, в Slack, email, Telegram) при превышении заданных порогов. Это позволяет оперативно реагировать на критические проблемы в инфраструктуре.
Пример работы системы:
Сбор метрик с хостов и сервисов:

На каждом сервере устанавливается node_exporter, который собирает метрики системы (CPU, RAM, Network, HDD).
Каждый микросервис должен публиковать свои метрики в формате, совместимом с Prometheus (например, с помощью встроенной библиотеки для разных языков программирования: Go, Python, Java и т.д.). Также можно использовать cAdvisor для мониторинга контейнеров.
Специфичные метрики, такие как задержки запросов, количество активных сессий или бизнес-метрики, можно экспортировать из самих микросервисов через библиотеки Prometheus.
Агрегация и хранение метрик: Prometheus периодически опрашивает все метрики и сохраняет их в своём хранилище. Эти данные хранятся в формате временных рядов, что позволяет анализировать их в динамике.

Визуализация и анализ: Grafana подключается к Prometheus как источник данных и предоставляет разработчикам и администраторам удобные дашборды для мониторинга. Каждый пользователь может настроить свои собственные панели для отслеживания состояния отдельных сервисов или всей системы.

Оповещения: При превышении установленных порогов, таких как высокий уровень использования CPU или недоступность сервиса, Alertmanager отправляет уведомления ответственным сотрудникам.

Преимущества решения:
Централизованный сбор метрик: Prometheus собирает метрики со всех хостов и сервисов в одном месте, что упрощает мониторинг и анализ.
Поддержка кастомных метрик: С помощью встроенных библиотек Prometheus можно легко добавлять специфичные метрики для каждого микросервиса.
Масштабируемость: Prometheus поддерживает большое количество таргетов, и его можно масштабировать горизонтально для обработки ещё большего объёма данных.
Удобная визуализация: Grafana предоставляет гибкий интерфейс для визуализации и анализа данных. Можно создавать как общие, так и детализированные дашборды для мониторинга конкретных сервисов.
Оповещения: Alertmanager обеспечивает оперативное уведомление о проблемах, что помогает своевременно реагировать на сбои в системе.
Агрегация и запросы: Grafana с PromQL предоставляет возможности для анализа данных в различных разрезах, включая агрегацию метрик по времени или по сервисам.
Дополнительные возможности:
Интеграция с другими системами: Grafana и Prometheus легко интегрируются с другими инструментами мониторинга и логирования, такими как Loki для логов, ELK Stack или Jaeger для трассировки запросов.
Долгосрочное хранение метрик: В случае необходимости долгосрочного хранения данных можно использовать решения вроде Thanos или Cortex, которые расширяют возможности хранения данных Prometheus.
Вывод:
Решение на основе Prometheus и Grafana является оптимальным для мониторинга микросервисной архитектуры. Оно предоставляет мощные инструменты для сбора, хранения, анализа и визуализации метрик со всех хостов и сервисов. Это решение полностью отвечает требованиям по мониторингу ресурсов системы, включая CPU, RAM, HDD и сеть, а также поддерживает кастомные метрики для каждого сервиса.




